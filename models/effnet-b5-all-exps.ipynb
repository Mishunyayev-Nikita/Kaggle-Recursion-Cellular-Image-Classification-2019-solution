{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 13 11:04:52 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P0    75W / 300W |   9554MiB / 16130MiB |     38%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   37C    P0    69W / 300W |   8852MiB / 16130MiB |     80%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   38C    P0    68W / 300W |   8852MiB / 16130MiB |     66%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   38C    P0    71W / 300W |   8852MiB / 16130MiB |     81%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  Off  | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   40C    P0    69W / 300W |   8852MiB / 16130MiB |     81%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  Off  | 00000000:00:09.0 Off |                    0 |\n",
      "| N/A   38C    P0    70W / 300W |   8852MiB / 16130MiB |     66%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  Off  | 00000000:00:0A.0 Off |                    0 |\n",
      "| N/A   39C    P0    67W / 300W |   8852MiB / 16130MiB |     61%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  Off  | 00000000:00:0B.0 Off |                    0 |\n",
      "| N/A   42C    P0    69W / 300W |   8852MiB / 16130MiB |     22%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     25733      C   /opt/anaconda3/bin/python                   9519MiB |\n",
      "|    1     25733      C   /opt/anaconda3/bin/python                   8817MiB |\n",
      "|    2     25733      C   /opt/anaconda3/bin/python                   8817MiB |\n",
      "|    3     25733      C   /opt/anaconda3/bin/python                   8817MiB |\n",
      "|    4     25733      C   /opt/anaconda3/bin/python                   8817MiB |\n",
      "|    5     25733      C   /opt/anaconda3/bin/python                   8817MiB |\n",
      "|    6     25733      C   /opt/anaconda3/bin/python                   8817MiB |\n",
      "|    7     25733      C   /opt/anaconda3/bin/python                   8817MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "package_path = 'EfficientNet-PyTorch/'\n",
    "sys.path.append(package_path)\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from radam import RAdam, PlainRAdam, AdamW\n",
    "from am_softmax import AMSoftmaxLoss, AngleSimpleLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torchvision import models, transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer\n",
    "from ignite.metrics import Loss, Accuracy\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "from ignite.handlers import  EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'SEED': 42,\n",
    "    'CLASSES': 1108,\n",
    "    'PATH_DATA': '/home/tienen/kaggle_dataset_drugs/',\n",
    "    'DEVICE': 'cuda',\n",
    "    'BATCH_SIZE': 4,\n",
    "    'VAL_SIZE': 0.05,\n",
    "    'MODEL_NAME': 'EffNet-b5_AMSLoss',\n",
    "    'USE_ANGULAR': True,\n",
    "    'USE_BN': True,\n",
    "    'LR': 1e-4,\n",
    "    'LR_STR': '1e-4',\n",
    "    'TURN_OFF_ON_N_EPOCHS': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    import random; import os\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_torch(config['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDS(D.Dataset):\n",
    "    def __init__(self, df, img_dir, mode='train', site=1,\n",
    "                 channels=[1,2,3,4,5,6], transforms=None):\n",
    "        self.records = df.to_records(index=False)\n",
    "        self.channels = channels\n",
    "        self.site = site\n",
    "        self.mode = mode\n",
    "        self.img_dir = img_dir\n",
    "        self.len = df.shape[0]\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_img_as_tensor(file_name):\n",
    "        with Image.open(file_name) as img:\n",
    "            return T.ToTensor()(img)\n",
    "\n",
    "    def _get_img_path(self, index, channel):\n",
    "        experiment, well, plate = self.records[index].experiment, self.records[index].well, self.records[index].plate\n",
    "        return '/'.join([self.img_dir,self.mode,experiment,f'Plate{plate}',f'{well}_s{self.site}_w{channel}.png'])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        paths = [self._get_img_path(index, ch) for ch in self.channels]\n",
    "        img = torch.cat([self._load_img_as_tensor(img_path) for img_path in paths])\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return img, int(self.records[index].sirna)\n",
    "        else:\n",
    "            return img, self.records[index].id_code\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(config['PATH_DATA']+'/train.csv')\n",
    "df_train, df_val = train_test_split(df, test_size=config['VAL_SIZE'], stratify=df.sirna, random_state=config['SEED'])\n",
    "df_test = pd.read_csv(config['PATH_DATA']+'/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>experiment</th>\n",
       "      <th>plate</th>\n",
       "      <th>well</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-01_1_B03</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B03</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-01_1_B04</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B04</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-01_1_B05</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B05</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-01_1_B06</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B06</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-01_1_B07</td>\n",
       "      <td>HEPG2-01</td>\n",
       "      <td>1</td>\n",
       "      <td>B07</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code experiment  plate well  sirna\n",
       "0  HEPG2-01_1_B03   HEPG2-01      1  B03    513\n",
       "1  HEPG2-01_1_B04   HEPG2-01      1  B04    840\n",
       "2  HEPG2-01_1_B05   HEPG2-01      1  B05   1020\n",
       "3  HEPG2-01_1_B06   HEPG2-01      1  B06    254\n",
       "4  HEPG2-01_1_B07   HEPG2-01      1  B07    144"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1 = ImagesDS(df_train, config['PATH_DATA'], site=1, mode='train')\n",
    "ds_2 = ImagesDS(df_train, config['PATH_DATA'], site=2, mode='train')\n",
    "ds = D.ConcatDataset([ds_1, ds_2])\n",
    "\n",
    "ds_val_1 = ImagesDS(df_val, config['PATH_DATA'], site=1, mode='train')\n",
    "ds_val_2 = ImagesDS(df_val, config['PATH_DATA'], site=2, mode='train')\n",
    "ds_val = D.ConcatDataset([ds_val_1, ds_val_2])\n",
    "\n",
    "ds_test_1 = ImagesDS(df_test, config['PATH_DATA'], site=1, mode='test')\n",
    "ds_test_2 = ImagesDS(df_test, config['PATH_DATA'], site=2, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = D.DataLoader(ds, batch_size=config['BATCH_SIZE'], shuffle=True, num_workers=4)\n",
    "val_loader = D.DataLoader(ds_val, batch_size=config['BATCH_SIZE'], shuffle=True, num_workers=4)\n",
    "\n",
    "test_loader_1 = D.DataLoader(ds_test_1, batch_size=1, shuffle=False, num_workers=4)\n",
    "test_loader_2 = D.DataLoader(ds_test_2, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EffNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000, num_channels=6, use_bn=False, use_angular=False):\n",
    "        super().__init__()\n",
    "        self.use_angular = use_angular\n",
    "        self.use_bn = use_bn\n",
    "        if self.use_bn:\n",
    "            self.bn = nn.BatchNorm2d(6)\n",
    "        \n",
    "        self.features = EfficientNet.from_pretrained('efficientnet-b5', num_classes=num_classes)\n",
    "        #print(self.features)\n",
    "        \n",
    "        trained_kernel = self.features._conv_stem.weight\n",
    "        new_conv = nn.Sequential(nn.Conv2d(num_channels, 48, kernel_size=(3,3), stride=(2,2), bias=False),\n",
    "                    nn.ZeroPad2d(padding=(0, 1, 0, 1)))\n",
    "        with torch.no_grad():\n",
    "            new_conv[0].weight[:,:] = torch.stack([torch.mean(trained_kernel, 1)]*6, dim=1)\n",
    "        self.features._conv_stem = new_conv\n",
    "        \n",
    "        if self.use_angular:\n",
    "            self.features._fc = AngleSimpleLinear(2048, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.use_bn:\n",
    "            x = self.bn(x)\n",
    "        out = self.features(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "model = EffNet(num_classes=config['CLASSES'], use_bn=config['USE_BN'], use_angular=config['USE_ANGULAR'])\n",
    "model.to(config['DEVICE']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = AMSoftmaxLoss(margin_type='cos')\n",
    "optimizer = RAdam(model.parameters(), lr=config['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'loss': Loss(criterion),\n",
    "    'accuracy': Accuracy(),\n",
    "}\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=config['DEVICE'])\n",
    "val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=config['DEVICE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach to our trainer a function to run a validator at the end of each epoch\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_and_display_val_metrics(engine):\n",
    "    epoch = engine.state.epoch\n",
    "    metrics = val_evaluator.run(val_loader).metrics\n",
    "    print(\"Validation Results - Epoch: {}  Average Loss: {:.4f} | Accuracy: {:.4f} \"\n",
    "          .format(engine.state.epoch, \n",
    "                      metrics['loss'], \n",
    "                      metrics['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this problem I think it's better not to use the same learning rate during all the training\n",
    "# let's make it decrease after each epoch\n",
    "lr_scheduler = ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def update_lr_scheduler(engine):\n",
    "    lr_scheduler.step()\n",
    "    lr = float(optimizer.param_groups[0]['lr'])\n",
    "    print(\"Learning rate: {}\".format(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We definitely need early stopping\n",
    "# I don't want to tune the number of epochs by hands\n",
    "handler = EarlyStopping(patience=4, score_function=lambda engine: - engine.state.metrics['loss'], trainer=trainer)\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's warmup our last linear layer by freezing all the other layers for a couple of epochs\n",
    "@trainer.on(Events.EPOCH_STARTED)\n",
    "def turn_on_layers(engine):\n",
    "    epoch = engine.state.epoch\n",
    "    if config['TURN_OFF_ON_N_EPOCHS'] > 0:\n",
    "        \n",
    "        if epoch == 1:\n",
    "            for name, child in model.named_children():\n",
    "                if name == 'bn':\n",
    "                    pbar.log_message(name + ' is unfrozen')\n",
    "                    for param in child.parameters():\n",
    "                        param.requires_grad = True\n",
    "\n",
    "                else:\n",
    "                    for child_name, child_2 in child.named_children():\n",
    "                        if child_name == '_fc':\n",
    "                            pbar.log_message(child_name + ' is unfrozen')\n",
    "                            for param in child_2.parameters():\n",
    "                                param.requires_grad = True\n",
    "                        else:\n",
    "                            for param in child_2.parameters():\n",
    "                                param.requires_grad = False\n",
    "                        \n",
    "        if epoch == config['TURN_OFF_ON_N_EPOCHS']+1:\n",
    "            pbar.log_message(\"Turn on all the layers\")\n",
    "            for name, child in model.named_children():\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, let's save our model's weights after some epochs to be able to use them later\n",
    "checkpoints = ModelCheckpoint(config['MODEL_NAME'], 'all_exps',\n",
    "                              save_interval=1, n_saved=10, create_dir=True, require_empty=False)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoints, {config['MODEL_NAME']+'_lr{}'.format(config['LR_STR']): model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we obviously need beautiful tqdm-based progress bars for our training process\n",
    "pbar = ProgressBar(bar_format='')\n",
    "pbar.attach(trainer, output_transform=lambda x: {'loss': x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's log some interesting information about our learning process to Tensorboard\n",
    "# (Does not work in kaggle kernels, you need to have TensorboadX installed)\n",
    "\n",
    "import os\n",
    "#  If we are not on kaggle server\n",
    "from ignite.contrib.handlers.tensorboard_logger import *\n",
    "tb_logger = TensorboardLogger(\"board/\"+config['MODEL_NAME'])\n",
    "tb_logger.attach(trainer, log_handler=OutputHandler(tag=\"training\", output_transform=lambda loss: {'loss': loss}),\n",
    "                 event_name=Events.ITERATION_COMPLETED)\n",
    "\n",
    "tb_logger.attach(val_evaluator, log_handler=OutputHandler(tag=\"validation\", metric_names=[\"accuracy\", \"loss\"],\n",
    "                 another_engine=trainer),event_name=Events.EPOCH_COMPLETED)\n",
    "tb_logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn is unfrozen\n",
      "_fc is unfrozen\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 1  Average Loss: 21.7935 | Accuracy: 0.0093 \n",
      "Learning rate: 9.5e-05\n",
      "Turn on all the layers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 2  Average Loss: 20.4002 | Accuracy: 0.0811 \n",
      "Learning rate: 9.025e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 3  Average Loss: 19.5701 | Accuracy: 0.1514 \n",
      "Learning rate: 8.573749999999999e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 4  Average Loss: 18.9303 | Accuracy: 0.2254 \n",
      "Learning rate: 8.145062499999998e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 5  Average Loss: 18.4109 | Accuracy: 0.2708 \n",
      "Learning rate: 7.737809374999998e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 6  Average Loss: 18.1274 | Accuracy: 0.2982 \n",
      "Learning rate: 7.350918906249998e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 7  Average Loss: 18.2632 | Accuracy: 0.2881 \n",
      "Learning rate: 6.983372960937497e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 8  Average Loss: 17.7273 | Accuracy: 0.3149 \n",
      "Learning rate: 6.634204312890622e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 9  Average Loss: 17.7046 | Accuracy: 0.3264 \n",
      "Learning rate: 6.30249409724609e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 10  Average Loss: 17.3643 | Accuracy: 0.3415 \n",
      "Learning rate: 5.987369392383786e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 11  Average Loss: 18.2613 | Accuracy: 0.3048 \n",
      "Learning rate: 5.688000922764596e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 12  Average Loss: 18.5068 | Accuracy: 0.2878 \n",
      "Learning rate: 5.4036008766263664e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 13  Average Loss: 17.4530 | Accuracy: 0.3554 \n",
      "Learning rate: 5.133420832795048e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 14  Average Loss: 16.9970 | Accuracy: 0.3765 \n",
      "Learning rate: 4.876749791155295e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fb29ade00e419ebe51dfe051c95f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17345), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=20) # 1e-4, gamma in scheduler=0.95, RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 14\n",
    "\n",
    "model = EffNet(num_classes=config['CLASSES'], use_angular=config['USE_ANGULAR'])\n",
    "checkpoint = torch.load('{0}/all_exps_{0}_lr{1}_{2}.pth'.format(config['MODEL_NAME'], config['LR_STR'], n_epochs))\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(config['DEVICE'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5025326d893b400d9d9b4f6f34c3c5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predicted = []  # predicted = np.empty(0)\n",
    "    for (x1, id1), (x2, id2) in tqdm_notebook(zip(test_loader_1, test_loader_2)):\n",
    "        x1 = x1.to(config['DEVICE'])\n",
    "        output1 = model(x1)\n",
    "        \n",
    "        x2 = x2.to(config['DEVICE'])\n",
    "        output2 = model(x2)\n",
    "        \n",
    "        result = 0.5*(output1 + output2)\n",
    "        predicted.append(result.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19897, 1108)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = np.stack(predicted).squeeze()\n",
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(config['PATH_DATA'] + '/test.csv')\n",
    "submission['sirna'] = np.argmax(predicted, axis=1).astype(int)\n",
    "submission.to_csv('submits/{}_{}epoch_lr{}.csv'.format(config['MODEL_NAME'], n_epochs, config['LR_STR']),\n",
    "                  index=False, columns=['id_code','sirna'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>experiment</th>\n",
       "      <th>plate</th>\n",
       "      <th>well</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-08_1_B03</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B03</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-08_1_B04</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B04</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-08_1_B05</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B05</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-08_1_B06</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B06</td>\n",
       "      <td>1054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-08_1_B07</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B07</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code experiment  plate well  sirna\n",
       "0  HEPG2-08_1_B03   HEPG2-08      1  B03    855\n",
       "1  HEPG2-08_1_B04   HEPG2-08      1  B04     79\n",
       "2  HEPG2-08_1_B05   HEPG2-08      1  B05    222\n",
       "3  HEPG2-08_1_B06   HEPG2-08      1  B06   1054\n",
       "4  HEPG2-08_1_B07   HEPG2-08      1  B07    307"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use plates leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2 3 1]\n",
      " [1 3 4 2]\n",
      " [2 4 1 3]\n",
      " [1 3 4 2]\n",
      " [3 1 2 4]\n",
      " [1 3 4 2]\n",
      " [1 3 4 2]\n",
      " [2 4 1 3]\n",
      " [1 3 4 2]\n",
      " [4 2 3 1]]\n"
     ]
    }
   ],
   "source": [
    "plate_groups = np.zeros((1108,4), int)\n",
    "for sirna in range(1108):\n",
    "    grp = df.loc[df.sirna==sirna,:].plate.value_counts().index.values\n",
    "    assert len(grp) == 3\n",
    "    plate_groups[sirna,0:3] = grp\n",
    "    plate_groups[sirna,3] = 10 - grp.sum()\n",
    "    \n",
    "print(plate_groups[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_exp = df_test.experiment.unique()\n",
    "\n",
    "group_plate_probs = np.zeros((len(all_test_exp),4))\n",
    "for idx in range(len(all_test_exp)):\n",
    "    preds = submission.loc[df_test.experiment == all_test_exp[idx],'sirna'].values\n",
    "    pp_mult = np.zeros((len(preds),1108))\n",
    "    pp_mult[range(len(preds)),preds] = 1\n",
    "    \n",
    "    sub_test = df_test.loc[df_test.experiment == all_test_exp[idx],:]\n",
    "    assert len(pp_mult) == len(sub_test)\n",
    "    \n",
    "    for j in range(4):\n",
    "        mask = np.repeat(plate_groups[np.newaxis, :, j], len(pp_mult), axis=0) == \\\n",
    "               np.repeat(sub_test.plate.values[:, np.newaxis], 1108, axis=1)\n",
    "        \n",
    "        group_plate_probs[idx,j] = np.array(pp_mult)[mask].sum()/len(pp_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HEPG2-08</th>\n",
       "      <td>0.186089</td>\n",
       "      <td>0.177958</td>\n",
       "      <td>0.191509</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEPG2-09</th>\n",
       "      <td>0.222924</td>\n",
       "      <td>0.340253</td>\n",
       "      <td>0.230144</td>\n",
       "      <td>0.206679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEPG2-10</th>\n",
       "      <td>0.485560</td>\n",
       "      <td>0.158845</td>\n",
       "      <td>0.181408</td>\n",
       "      <td>0.174188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEPG2-11</th>\n",
       "      <td>0.521700</td>\n",
       "      <td>0.147378</td>\n",
       "      <td>0.188065</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUVEC-17</th>\n",
       "      <td>0.715704</td>\n",
       "      <td>0.098375</td>\n",
       "      <td>0.078520</td>\n",
       "      <td>0.107401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3\n",
       "HEPG2-08  0.186089  0.177958  0.191509  0.444444\n",
       "HEPG2-09  0.222924  0.340253  0.230144  0.206679\n",
       "HEPG2-10  0.485560  0.158845  0.181408  0.174188\n",
       "HEPG2-11  0.521700  0.147378  0.188065  0.142857\n",
       "HUVEC-17  0.715704  0.098375  0.078520  0.107401"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(group_plate_probs, index=all_test_exp).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 0 0 0 0 2 2 3 0 0 3 1 0 0 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "exp_to_group = group_plate_probs.argmax(1)\n",
    "print(exp_to_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the function that sets 75% of the sirnas to zero according to the selected assignment\n",
    "\n",
    "def select_plate_group(pp_mult, idx):\n",
    "    sub_test = df_test.loc[df_test.experiment == all_test_exp[idx],:]\n",
    "    assert len(pp_mult) == len(sub_test)\n",
    "    mask = np.repeat(plate_groups[np.newaxis, :, exp_to_group[idx]], len(pp_mult), axis=0) != \\\n",
    "           np.repeat(sub_test.plate.values[:, np.newaxis], 1108, axis=1)\n",
    "    pp_mult[mask] = 0\n",
    "    return pp_mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = submission.copy()\n",
    "\n",
    "for idx in range(len(all_test_exp)):\n",
    "    indices = (df_test.experiment == all_test_exp[idx])\n",
    "    preds = predicted[indices, :].copy()\n",
    "    \n",
    "    preds = select_plate_group(preds, idx)\n",
    "    sub.loc[indices,'sirna'] = preds.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5653616123033623"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sub.sirna == submission.sirna).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submits/{}_{}epochs_lr{}_plates_leak.csv'.format(config['MODEL_NAME'], n_epochs, config['LR_STR']),\n",
    "           index=False, columns=['id_code','sirna'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1092, 1103)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission.sirna.unique()), len(sub.sirna.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>experiment</th>\n",
       "      <th>plate</th>\n",
       "      <th>well</th>\n",
       "      <th>sirna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-08_1_B03</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B03</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-08_1_B04</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B04</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-08_1_B05</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B05</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-08_1_B06</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B06</td>\n",
       "      <td>1054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-08_1_B07</td>\n",
       "      <td>HEPG2-08</td>\n",
       "      <td>1</td>\n",
       "      <td>B07</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_code experiment  plate well  sirna\n",
       "0  HEPG2-08_1_B03   HEPG2-08      1  B03    855\n",
       "1  HEPG2-08_1_B04   HEPG2-08      1  B04     79\n",
       "2  HEPG2-08_1_B05   HEPG2-08      1  B05    814\n",
       "3  HEPG2-08_1_B06   HEPG2-08      1  B06   1054\n",
       "4  HEPG2-08_1_B07   HEPG2-08      1  B07    609"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
